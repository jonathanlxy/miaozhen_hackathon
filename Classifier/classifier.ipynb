{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    " # Table of Contents\n",
    "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\" id=\"toc-level0\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded succeed\n",
      ">> Synonyms on loading ...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import synonyms\n",
    "import jieba\n",
    "import jieba.posseg as pseg\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "height has been deprecated.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corpus_df = pd.read_csv('./corpus.csv').reset_index(drop = True)\n",
    "corpus_2_list = corpus_df[corpus_df['rate'] == 2]['token'].tolist()\n",
    "corpus_3_list = corpus_df[corpus_df['rate'] == 3]['token'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rate_token(token, corpus_3, corpus_2):\n",
    "    '''\n",
    "    Input: One token\n",
    "    Output: Rate \n",
    "    '''\n",
    "    if token in corpus_3:\n",
    "        return 3\n",
    "    elif token in corpus_2:\n",
    "        return 2\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rate_title_tokens(tokens):\n",
    "    token_rates = list(map(token_rater, tokens))\n",
    "    return token_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rate_title_syns(tokens):\n",
    "    \n",
    "    syn_3_cnt = 0\n",
    "    syn_2_cnt = 0\n",
    "    syn_cnt_list = []\n",
    "    \n",
    "    for token in tokens:\n",
    "        syn = synonyms.nearby(token)[0]\n",
    "        syn_rates = list(map(token_rater, syn))\n",
    "\n",
    "        syn_cnt = [2 if syn_rates.count(3) < syn_rates.count(2) else(0 if syn_rates.count(3) == 0 and syn_rates.count(2) == 0 else 3)]\n",
    "        syn_cnt_list += syn_cnt\n",
    "        \n",
    "    return syn_cnt_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def title_processor(title):\n",
    "    \n",
    "    tokens = list(set(list(jieba.cut_for_search(title))))\n",
    "\n",
    "    token_cnt_list = np.array(title_token_rater(tokens))\n",
    "    syn_cnt_list = np.array(title_syn_rater(tokens))\n",
    "    \n",
    "    token_non_zero = np.where(token_cnt_list > 0)\n",
    "    syn_cnt_list = np.delete(syn_cnt_list, token_non_zero)\n",
    "            \n",
    "    token_cnt_list = token_cnt_list.tolist()\n",
    "    syn_cnt_list = syn_cnt_list.tolist()\n",
    "    \n",
    "    syn_3_cnt = syn_cnt_list.count(3)\n",
    "    syn_2_cnt = syn_cnt_list.count(2)\n",
    "    token_3_cnt = token_cnt_list.count(3)\n",
    "    token_2_cnt = token_cnt_list.count(2)\n",
    "    \n",
    "    return [token_2_cnt, token_3_cnt, syn_2_cnt, syn_3_cnt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# miaozhen sample dataset\n",
    "\n",
    "training_title_list = open('/Users/olap/Desktop/training_title_list.txt', 'r').read().split('\\n')[:100]\n",
    "title_feature_list = list(map(title_processor, training_title_list))\n",
    "\n",
    "ture_label = open('/Users/olap/Desktop/training_set.txt', 'r').read().split('\\n')\n",
    "true_label_list = list(map(lambda x:x.split(' ')[-1], ture_label))\n",
    "true_label_list = [1 if label=='0' else label for label in true_label_list]\n",
    "true_label_list = [0 if label=='100' else label for label in true_label_list][:-1]\n",
    "\n",
    "title = pd.DataFrame(training_title_list)\n",
    "feature = pd.DataFrame(title_feature_list)\n",
    "true_label = pd.DataFrame(true_label_list)\n",
    "\n",
    "noobs_df = pd.concat([title, feature, true_label], axis= 1)\n",
    "noobs_df.columns = ['title', 'token_2', 'token_3', 'syn_2', 'syn_3', 'true_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# yewai title\n",
    "\n",
    "yewai_df = pd.read_csv('/Users/olap/Desktop/yw_title.csv').drop('Unnamed: 0', axis  = 1)\n",
    "\n",
    "yewai_df = yewai_df[yewai_df.true_label.notnull()].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "lr = linear_model.LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_perfermance(data, test_size, model, diff):\n",
    "    \n",
    "    title_list = data['title'].tolist()\n",
    "    X = np.array(list(map(title_processor, title_list)))\n",
    "    y = np.array(data['true_label'].tolist())\n",
    "    \n",
    "    title = pd.DataFrame(title_list)\n",
    "    feature = pd.DataFrame(X)\n",
    "    true_label = pd.DataFrame(y)\n",
    "\n",
    "    df = pd.concat([title, feature, true_label], axis= 1)\n",
    "    df.columns = ['title', 'token_2', 'token_3', 'syn_2', 'syn_3', 'true_label']\n",
    "    \n",
    "    # split data\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=test_size, random_state=0)\n",
    "    \n",
    "    for train_index, test_index in sss.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    #train model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    print('traning acc', model.score(X_train, y_train))\n",
    "    print('test acc', model.score(X_test, y_test))\n",
    "\n",
    "    # predicted probalibility\n",
    "    model_predict = pd.DataFrame(model.predict(X_test))\n",
    "    model_predict.columns = ['pred_label']\n",
    "    model_proba = pd.DataFrame(model.predict_proba(X_test))\n",
    "    model_proba.columns = ['proba_0', 'proba_1']\n",
    "    \n",
    "    #get test set\n",
    "    index = test_index.tolist()\n",
    "    test_df = df.iloc[index].reset_index(drop = True)\n",
    "    test_df = pd.concat([test_df, model_predict, model_proba], axis= 1)\n",
    "    \n",
    "    # rule base perfermance    \n",
    "    rule_base_mis = len(test_df[((test_df['token_3'] == 0) & (test_df['true_label'] == 1))\n",
    "             | (test_df['token_3'] > 0) & (test_df['true_label'] == 0)])\n",
    "    \n",
    "    print('rule base acc', 1-rule_base_mis/len(test_df))\n",
    "    \n",
    "    # mistake cases\n",
    "    mis_df = test_df[test_df['true_label'] != test_df['pred_label']]\n",
    "    \n",
    "    # title rated manually\n",
    "    manual_rating_df = test_df[abs(test_df['proba_0']-test_df['proba_1']) < diff] \n",
    "    manual_rating_cnt = len(manual_rating_df)\n",
    "    manual_improve_cnt = len(test_df[(test_df['true_label'] != test_df['pred_label'])\n",
    "                            & (abs(test_df['proba_0']-test_df['proba_1']) < diff)])\n",
    "    \n",
    "    print('test_count', len(test_df))\n",
    "    print('manually rate title', manual_rating_cnt)\n",
    "    print('can improve', manual_improve_cnt)\n",
    "    \n",
    "    if manual_rating_cnt != 0:\n",
    "        print('manyally eff', manual_improve_cnt/manual_rating_cnt)\n",
    "    \n",
    "    print('model + manual acc', model.score(X_test, y_test) + manual_improve_cnt/len(test_df))\n",
    "    \n",
    "    #return mistake cases to imporve model/corpus\n",
    "    return mis_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traning acc 0.9\n",
      "test acc 0.95\n",
      "rule base acc 0.875\n",
      "test_count 40\n",
      "manually rate title 10\n",
      "can improve 2\n",
      "manyally eff 0.2\n",
      "model + manual acc 1.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>token_2</th>\n",
       "      <th>token_3</th>\n",
       "      <th>syn_2</th>\n",
       "      <th>syn_3</th>\n",
       "      <th>true_label</th>\n",
       "      <th>pred_label</th>\n",
       "      <th>proba_0</th>\n",
       "      <th>proba_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>分手你还赚了一个处，你不亏！</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.544775</td>\n",
       "      <td>0.455225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>舆情分析：兰陵一副校长致初中女生\"怀孕\" - 案例库 - 华声舆情 - 华声在线</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.506143</td>\n",
       "      <td>0.493857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      title  token_2  token_3  syn_2  syn_3  true_label  pred_label   proba_0   proba_1\n",
       "2                            分手你还赚了一个处，你不亏！        1        0      0      0           1           0  0.544775  0.455225\n",
       "7  舆情分析：兰陵一副校长致初中女生\"怀孕\" - 案例库 - 华声舆情 - 华声在线        1        0      1      0           1           0  0.506143  0.493857"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_perfermance(noobs_df, .4, lr, .3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
