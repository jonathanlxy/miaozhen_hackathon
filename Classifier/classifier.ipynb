{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    " # Table of Contents\n",
    "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\" id=\"toc-level0\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded succeed\n",
      ">> Synonyms on loading ...\n",
      ">> Synonyms vocabulary size: 125792\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import synonyms\n",
    "import jieba\n",
    "import jieba.posseg as pseg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "height has been deprecated.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.height', 1000)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corpus_df = pd.read_csv('/Users/olap/Desktop/corpus.csv')\n",
    "corpus_2_list = corpus_df[corpus_df['rate'] == 2]['token'].tolist()\n",
    "corpus_3_list = corpus_df[corpus_df['rate'] == 3]['token'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def title_token_rater(tokens):\n",
    "    \n",
    "    tokens_rate = list(map(lambda x:3 if x in corpus_3_list else(2 if x in corpus_2_list else 0), tokens))\n",
    "        \n",
    "    token_3_cnt = tokens_rate.count(3)\n",
    "    token_2_cnt = tokens_rate.count(2)\n",
    "    \n",
    "    return [token_2_cnt, token_3_cnt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def title_syn_rater(tokens):\n",
    "    \n",
    "    syn_3_cnt = 0\n",
    "    syn_2_cnt = 0\n",
    "    syn_cnt_list = []\n",
    "    \n",
    "    for token in tokens:\n",
    "        syn = synonyms.nearby(token)[0]\n",
    "        syn_rates = list(map(lambda x:3 if x in corpus_3_list else(2 if x in corpus_2_list else 0), syn))\n",
    "\n",
    "        syn_cnt = [2 if syn_rates.count(3) < syn_rates.count(2) else(0 if syn_rates.count(3) == 0 and syn_rates.count(2) == 0 else 3)]\n",
    "        syn_cnt_list += syn_cnt\n",
    "        \n",
    "    syn_3_cnt = syn_cnt_list.count(3)\n",
    "    syn_2_cnt = syn_cnt_list.count(2)\n",
    "     \n",
    "    return [syn_2_cnt, syn_3_cnt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def title_processor(title):\n",
    "    \n",
    "    tokens = list(set(list(jieba.cut_for_search(title))))\n",
    "#     print(tokens)\n",
    "    token_rate = title_token_rater(tokens)\n",
    "    syn_rate = title_syn_rater(tokens)\n",
    "    \n",
    "    return token_rate + syn_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/qt/bjwlshwn1gv_4s_c_97p0s440000gn/T/jieba.cache\n",
      "Loading model cost 0.940 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "training_title_list = open('/Users/olap/Desktop/training_title_list.txt', 'r').read().split('\\n')[:100]\n",
    "title_feature_list = list(map(title_processor, training_title_list))\n",
    "\n",
    "ture_label = open('/Users/olap/Desktop/training_set.txt', 'r').read().split('\\n')\n",
    "title_rate = open('/Users/olap/Desktop/title_rate.csv', 'r').read().split('\\n')\n",
    "true_label_list = list(map(lambda x:x.split(' ')[-1], ture_label))\n",
    "true_label_list = [1 if label=='0' else label for label in true_label_list]\n",
    "true_label_list = [0 if label=='100' else label for label in true_label_list][:-1]\n",
    "\n",
    "label_list = list(map(lambda x:x.split(',')[-1], title_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "title = pd.DataFrame(training_title_list)\n",
    "feature = pd.DataFrame(title_feature_list)\n",
    "true_label = pd.DataFrame(true_label_list)\n",
    "\n",
    "noobs_df = pd.concat([title, feature, true_label], axis= 1)\n",
    "noobs_df.columns = ['Title', 'token_2', 'token_3', 'syn_2', 'syn_3', 'true_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def processor_testing(title, rate):\n",
    "    tokenized_title = list(set(list(jieba.cut_for_search(title))))\n",
    "    for token in tokenized_title:\n",
    "    #     print (token)\n",
    "        token_syn = [token] + synonyms.nearby(token)[0]\n",
    "        print (token_syn)\n",
    "        \n",
    "        if rate == 2:\n",
    "            print (list(map(lambda x:x in corpus_2_list, token_syn)))\n",
    "        if rate == 3:\n",
    "            print (list(map(lambda x:x in corpus_3_list, token_syn)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X = np.array(noobs_df.iloc[:,1:5])\n",
    "y = np.array(noobs_df.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.5, random_state=0)\n",
    "sss.get_n_splits(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [66 70 58 78 54 30  2 95 68  5 35 17 75 88 87 79 37  1 59 46 71 92 38 69 91\n",
      " 15  7 62 10 76 45 72 53 64 31  8 56 80 11 63 89 77 22 57 16 42  4 65 40 36] TEST: [61 23 49 60 13 94 50  0 18 19 98 27 39 26 28 73 85 67 74 82 41 86 44 81 25\n",
      "  3 93 32 96 97 52 84 33 99 83 55 14 24 21 43 51 12 29 34 47  6  9 20 90 48]\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in sss.split(X, y):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "model = linear_model.LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90000000000000002"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)\n",
    "model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90000000000000002"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_predict = pd.DataFrame(model.predict(X_test))\n",
    "model_predict.columns = ['model_pred']\n",
    "model_proba = pd.DataFrame(model.predict_proba(X_test))\n",
    "model_proba.columns = ['proba_0', 'proba_1']\n",
    "\n",
    "index = test_index.tolist()\n",
    "noobs_df_test = noobs_df.iloc[index].loc[:, noobs_df.columns != 'label'].reset_index(drop = True)\n",
    "noobs_df_test = pd.concat([noobs_df_test, model_predict, model_proba], axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>token_2</th>\n",
       "      <th>token_3</th>\n",
       "      <th>syn_2</th>\n",
       "      <th>syn_3</th>\n",
       "      <th>true_label</th>\n",
       "      <th>model_pred</th>\n",
       "      <th>proba_0</th>\n",
       "      <th>proba_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>舆情分析：兰陵一副校长致初中女生\"怀孕\" - 案例库 - 华声舆情 - 华声在线</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.566844</td>\n",
       "      <td>0.433156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>分手你还赚了一个处，你不亏！</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.566844</td>\n",
       "      <td>0.433156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>网络惊现售卖原味丝袜二手内裤 交易背后不堪入目_新闻频道_中华网</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.109978</td>\n",
       "      <td>0.890022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>外围女真实生活揭秘：一夜遍体鳞伤换来30万_食神的神_食神的神的和讯博客</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.805167</td>\n",
       "      <td>0.194833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>大尺度无底线直播 – 【人人分享-人人网】</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.122308</td>\n",
       "      <td>0.877692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>大麻会对生活造成危害吗？ - 知乎</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.814424</td>\n",
       "      <td>0.185576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>【福利/欢乐向/AMV】新年就要啪啪啪 我可能遇见了假啪啪啪啪@FB_JAMes_MAD·A...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.814424</td>\n",
       "      <td>0.185576</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Title  token_2  token_3  syn_2  syn_3  true_label  model_pred   proba_0   proba_1\n",
       "2            舆情分析：兰陵一副校长致初中女生\"怀孕\" - 案例库 - 华声舆情 - 华声在线        1        0      1      0           1           0  0.566844  0.433156\n",
       "5                                      分手你还赚了一个处，你不亏！        1        0      1      0           1           0  0.566844  0.433156\n",
       "21                   网络惊现售卖原味丝袜二手内裤 交易背后不堪入目_新闻频道_中华网        3        0      2      0           1           1  0.109978  0.890022\n",
       "22               外围女真实生活揭秘：一夜遍体鳞伤换来30万_食神的神_食神的神的和讯博客        0        0      1      0           1           0  0.805167  0.194833\n",
       "29                              大尺度无底线直播 – 【人人分享-人人网】        3        0      0      0           1           1  0.122308  0.877692\n",
       "31                                  大麻会对生活造成危害吗？ - 知乎        0        0      0      0           1           0  0.814424  0.185576\n",
       "34  【福利/欢乐向/AMV】新年就要啪啪啪 我可能遇见了假啪啪啪啪@FB_JAMes_MAD·A...        0        0      0      0           1           0  0.814424  0.185576"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keyword based model mistake cases\n",
    "noobs_df_test[((noobs_df_test['token_3'] == 0) & (noobs_df_test['true_label'] == 1))\n",
    "             | (noobs_df_test['token_3'] > 0) & (noobs_df_test['true_label'] == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>token_2</th>\n",
       "      <th>token_3</th>\n",
       "      <th>syn_2</th>\n",
       "      <th>syn_3</th>\n",
       "      <th>true_label</th>\n",
       "      <th>model_pred</th>\n",
       "      <th>proba_0</th>\n",
       "      <th>proba_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>舆情分析：兰陵一副校长致初中女生\"怀孕\" - 案例库 - 华声舆情 - 华声在线</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.566844</td>\n",
       "      <td>0.433156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>分手你还赚了一个处，你不亏！</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.566844</td>\n",
       "      <td>0.433156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>外围女真实生活揭秘：一夜遍体鳞伤换来30万_食神的神_食神的神的和讯博客</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.805167</td>\n",
       "      <td>0.194833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>大麻会对生活造成危害吗？ - 知乎</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.814424</td>\n",
       "      <td>0.185576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>【福利/欢乐向/AMV】新年就要啪啪啪 我可能遇见了假啪啪啪啪@FB_JAMes_MAD·A...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.814424</td>\n",
       "      <td>0.185576</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Title  token_2  token_3  syn_2  syn_3  true_label  model_pred   proba_0   proba_1\n",
       "2            舆情分析：兰陵一副校长致初中女生\"怀孕\" - 案例库 - 华声舆情 - 华声在线        1        0      1      0           1           0  0.566844  0.433156\n",
       "5                                      分手你还赚了一个处，你不亏！        1        0      1      0           1           0  0.566844  0.433156\n",
       "22               外围女真实生活揭秘：一夜遍体鳞伤换来30万_食神的神_食神的神的和讯博客        0        0      1      0           1           0  0.805167  0.194833\n",
       "31                                  大麻会对生活造成危害吗？ - 知乎        0        0      0      0           1           0  0.814424  0.185576\n",
       "34  【福利/欢乐向/AMV】新年就要啪啪啪 我可能遇见了假啪啪啪啪@FB_JAMes_MAD·A...        0        0      0      0           1           0  0.814424  0.185576"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ML model mistake cases\n",
    "noobs_df_test[noobs_df_test['true_label'] != noobs_df_test['model_pred']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
